{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My first Machine learning project building and deployment using kubernetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisModelTrainer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        iris = load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "    def train_model(self):\n",
    "        self.model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        return f1\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self.model, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.974320987654321\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainer = IrisModelTrainer()\n",
    "    trainer.load_data()\n",
    "    trainer.train_model()\n",
    "    score = trainer.evaluate_model()\n",
    "    print(\"F1 Score: \", score)\n",
    "    trainer.save('iris_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from typing import List\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_FILE_NAME\"] = 'iris_model.pkl'\n",
    "\n",
    "model_file_name = os.getenv(\"MODEL_FILE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model \n",
    "with open('iris_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "# fast api Application \n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input data model\n",
    "class IrisData(BaseModel):\n",
    "    septal_length: float\n",
    "    septal_width: float\n",
    "    petal_length: float\n",
    "    petal_width: float\n",
    "    \n",
    "# Define output data model\n",
    "class IrisResponse(BaseModel):\n",
    "    prediction: str\n",
    "    \n",
    "# Define the prediction function \n",
    "def predict_iris_species(input_data):\n",
    "    # convert the input data into numpy array \n",
    "    input_array = np.array([input_data.septal_length, input_data.septal_width, input_data.petal_length, input_data.petal_width]).reshape(1, -1)\n",
    "    \n",
    "    # make prediction using the loaded model \n",
    "    prediction = model.predict(input_array)[0]\n",
    "    \n",
    "    # map integer prediction to corresponding species name\n",
    "    species_map = {\n",
    "        0 : 'Iris Setosa',\n",
    "        1 : 'Iris Versicolour',\n",
    "        2 : 'Iris Verginica'\n",
    "    }\n",
    "    \n",
    "    prediction_name = species_map[prediction]\n",
    "    \n",
    "    # return the prediction result \n",
    "    return IrisResponse(prediction=prediction_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the end point for single prediction\n",
    "@app.post(\"/predict\")\n",
    "def predict_single(data: IrisData):\n",
    "    return predict_iris_species(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endpoint for batch prediction\n",
    "@app.post(\"/predict_batch\")\n",
    "def predict_batch(data: List[IrisData]):\n",
    "    predictions = [predict_iris_species(item) for item in data]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mohamedabokahf/Desktop/Text_web_mining/play'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path().resolve().as_posix() + '/play'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
